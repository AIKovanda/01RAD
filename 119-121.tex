\section*{2) Zpětná eliminace (backward elimination)}
Začneme s plným modelem a v každém kroku odstraníme jednu proměnnou, která nejméně přispívá modelu (měřeno F stat) nebo jejíž odstranění znamená největší zlepšení modelu (měřeno AIC).
\subsection*{algoritmus:}\begin{enumerate}[	1)]
	\item Naladíme model se všemi proměnnými.
	\item Pro každou proměnnou spočteme částečnou $\FF$ statistiku (nebo $t$-statistiku) jako by právě byla přidána do modelu, tzn. za předpokladu, že ostatní proměnné tam už jsou.
	\item Pokud je nějaká $\FF$-statistika menší, než kritická hodnota $\FF_\mathrm{OUT}$, vynecháme z modelu proměnnou s nejnižší hodnotou $\FF$. $\FF_\mathrm{OUT}=\FF_{1-\alpha_\mathrm{OUT}}(1,n-p)$, kde $p$ je aktuální počet regresorů v modelu, včetně interceptu, $\alpha_\text{OUT}=0.05,0.1,...$
	\item Opakujeme kroky 2) a 3), dokud všechny částečné $\FF$ statistiky nejsou větší, než příslušná kritická hodnota $\FF_\mathrm{OUT}$, tzn. nelze už vyřadit žádnou proměnnou.
\end{enumerate}
\begin{remark}
	Místo $\FF$ lze foužívat AIC.
\end{remark}

\section*{3) Dopředná regrese (forward regression)}
Začneme pouze s interceptem (nebo nutným minimálním modelem) a v každém kroku přidáme jednu proměnnou, která má za následek největší zlepšení modelu (největší nárůst $\FF$ nebo největší pokles AIC). 

Tato metoda neumožňuje odstranit proměnnou, která už do modelu byla přidána.

\subsection*{algoritmus:}\begin{enumerate}[	1)]
	\item Naladíme minimální model.
	\item Pro každou dostupnou proměnnou spošteme $\FF$ statistiku pro test významnosti jijího přidání do modelu.
	\item Pokud některá z těchto $\FF$ statistik překračuje kritickou hodnotu $\FF_\mathrm{in}$, přidáme do modelu proměnnou s nejvyšší hodnotou $\FF$ statistiky.
	\item Opakujeme kroky 2) a 3), dokud všechny $\FF$-statistiky pro zbývající proměnné nebudou menší, než $\FF_\mathrm{in}$ nebo dokud nezbyde žádná proměnná na přidání do modelu.
\end{enumerate}
\begin{remark}
	I když tento postup zjednodušuje výběr modelu, často bohužel vede na zařazení proměnných, které nemají významný příspěvek, jakmile jsou zařazeny další proměnné.
\end{remark}

\section*{3) Postupná regrese (stepwise regression)}
Kombinace dvou předchozích metod. V každém kroku algoritmu přidáváme jednu proměnnou a poté zkontrolujeme, zda není možné nějakou odebrat. Budeme potřebovat  dvě kritické hodnoty $\FF_\mathrm{in}$, $\FF_\mathrm{OUT}$ (pro použití $\FF$ statistiky).

\subsection*{algoritmus:}\begin{enumerate}[	1)]
	\item Naladíme minimální model.
	\item Zjistíme, zda přidání nějaké další proměnné může zlepšit model ($\FF$ nebo AIC). Pokud ano, přidáme do modelu proměnnou, která má za následek největší zlepšení modelu (nebo největší pokles AIC).
	\item V novém modelu zjistíme, zda nelze některou proměnnou vynechat (opět pomocí AIC nebo $\FF$). Pokud ano, vynecháme proměnnou, jejíž vyřazení má za následek největší zlepšení modelu (nebo největší pokles AIC).
	\item Opakujeme kroky 2) a 3) do té doby, až nebude možné přidat ani ubrat žádnou proměnnou.
\end{enumerate}

\section*{POZN) Princip marginality}\begin{enumerate}[	1)]
	\item Pokud jsou v modelu vyšší mocniny nějakého regressoru, měly by tam být obsaženy i všechny jeho nižší mocniny (i když jsou případně nevýznamné).
	\item Pokud je v modelu obsažena interakce dvou regressorů, měly by tam být i oba individuální regresory.
	\item Skaždou interakcí vyššího řádu by měl model obsahovat i všechny interakce řádu nižšího. ($a:b:c~\to~a:b,a:c,b:c$).
\end{enumerate}
\begin{remark}
	Jakmile nalezneme optimální model, je třeba řádně ověřit adekvátnost.
\end{remark}