\chapter{21-30}
\begin{remark}
	Někdy dopředu známe kandidáta $b_1$ jako hodnotu parametru $\beta_1$ a~chtěli bychom testovat 
	$\hypothesis{\beta_1=b_1}{\beta_1\neq b_1}$. Test bude zamítnut $H_0$, pokud 
	$$ \abs{\beta_1-b_1}\cdot \frac{\sqrt{S_{xx}}}{s_n}> t_{1-\frac{\alpha}{2}}(n-2). $$
\end{remark}
\subsection{Test významnosti interceptu}
Otázka je, zda přímka prochází počátkem $(0,0)$, tedy $\hypothesis{\beta_0=0}{\beta_0\neq0}$. Nezamítnutí $H_0$ znamená, že jednodušší model $y=\beta_1 x+e$ lépe popisuje datta, než $y=\beta_0+\beta_1 x+e$. $H_0$ potom zamítneme, pokud
$$ T_n=\frac{|\widehat{\beta}_0|}{\widehat{\sigma}(\widehat{\beta}_0)}=|\widehat{\beta}_0|\frac{1}{s_n\sqrt{\frac{1}{n}+\frac{\overline{x}^2}{S_{xx}}}}>t_{1-\frac{\alpha}{2}}(n-2). $$

\subsection{ANOVA přístup pro~testování}
Odvodili jsme $t$-test významnosti koeficientů a~nyní odvodíme ekvivalentní $F$-test, který může být zobecněn na~test celkové významnosti vícerozměrného regresního modelu (testy významnosti jednotlivých koeficientů mohou být totiž zavádějící). 

Myšlenkou metody (analýza rozptylu ANOVA) je určit, kolik variability v~pozorováních $(y_1,y_2,...,y_n)$ je "vysvětleno" regresním modelem (přímkou). Míru variability v~datech pak spočítáme jako podíl součtu sum od~regrese a~celkového počtu čtverců, tedy
$$ \SST=\sum_{i=1}^{n}(y_i-\overline{y}_n)^2, $$
pokud regresní přímka $y=\widehat{\beta}_0+\widehat{\beta}_1 x$ dobře prokládá data, tedy $\widehat{y}_i\approx y_i$. Dále bude platit, že 
$$ \sumin (\hyi-\lhyn)^2\approx\sumin (y_i-\lyn)^2. $$
Ukážeme, že $\lhy=\lyn$ a~tak 
$$ \sumin(\hyi-\lhyn)^2=\sumin (\hyi-\lyn)^2=\SSR $$ regresi sum ob squares, regresní součet čtverců. Podíl
$$ \RMR^2=\frac{\SSR}{\SST}=\frac{\sumin (\hyi-\lyn)^2}{\sumin (y_i-\lyn)^2}$$ tak vyjadřuje variabilitu v~$(y_1,...,y_n)$ vysvětlené regresním modelem. 

$\RMR^2$ - \textit{koeficient determinace (coefficient of determination)} (pro každý model by měl mít hodnotu $\RMR^2\approx 1$). Ukážeme, že $\RMR^2$ je kvadrát výběrového korelačního koeficientu mezi~$\textbf{x}$ a~$\textbf{y}$, což dává statistice $\RMR^2$ význam míry "dobré shody". 

Pokud bychom znali rozdělení pravděpodobnostní statistiky $\RMR^2$, nabízí se~její použití pro~test $H_0:~\beta_1=0$, kterou bychom zamítli, pokud bude $\RMR^2\approx1$. Protože každá monotonní funkce $\RMR^2$ vede na~ekvivalentní test, budeme uvažovat statistiku $$ \mathrm{F}=\frac{(n-2)\RMR}{1-\RMR^2}. $$

\begin{lemma}\label{lemma_k_vete}
	Nechť $\widehat{e}_i=y_i-\hyi$ značí rezidua, kde $\hyi=\wbeta_0+\wbeta_1 x_i$ a~$ \wbeta_0,\wbeta_1$ jsou LSE. Potom \begin{enumerate}
		\item $\sumin\widehat{e}_i=0$,
		\item $\lhyn=\lyn$,
		\item $\sumin \widehat{e}_i\hyi=0$.
	\end{enumerate}
\begin{proof}
	\begin{enumerate}
		\item Z~rovnice $\frac{\partial S}{\partial\beta_0}=0$ dostaneme $$ 0=\sumin (y_i-\wbeta_0-\wbeta_1 x_i)=\sumin(y_i-\hyi)=\sumin \widehat{e}_i.$$
		\item Z~bodu 1) plyne, že $\sumin\hyi=\sumin y_i$, podělením $n$ dostaneme dokazované tvrzení.
		\item Z~rovnice $\frac{\partial S}{\partial\beta_1}=0$ dostaneme $$0=\sumin(y_i-\wbeta_0-\wbeta_1 x_i)x_i=\sumin \hei x_i$$ a~tedy $$ \sumin \hei\hyi=\sumin \hei (\wbeta_0+\wbeta_1 x_i)=\sumin\hei\wbeta_0+\sumin x_i \hei\wbeta_1=\wbeta_0\underbrace{\sumin \hei}_{=0}+\wbeta_1\underbrace{\sumin x_i\hei}_{=0}=0.$$
	\end{enumerate}
\end{proof}
\end{lemma}
\begin{theorem}
	Předpokládejme, že $\SST\neq 0$. Potom platí\begin{enumerate}
		\item $0\leq \RMR^2\leq1$,
		\item $\RMR^2=1-\frac{\SSE}{\SST}$, kde $\SSE=\sumin(y_i-\hyi)^2$ jako reziduální součet čtverců,
		\item $\RMR^2=1~\Leftrightarrow~(\forall i~\in\hat{n})(\hyi=y_i)$ (všechna data leží na~přímce),
		\item pokud označíme $\textbf{x}=(x_1,...,x_n)$ a~$\textbf{y}=(y_1,...,y_n)$, potom $\RMR^2=\rho^2(\textbf{x},\textbf{y})$, kde $$\rho(\textbf{x},\textbf{y})=\frac{\Big(\sumin(x_i-\overline{x}_n)(y_i-\lyn)\Big)^2}{S_{xx}S_{yy}}$$ je druhá mocnina výběrového korelačního koeficientu vektorů $\textbf{x},\textbf{y}$,
		\item $\mathrm{F}=\frac{\SSR}{s_n^2}=\mathrm{T}^2$,
		\item pokud jsou chyby $e_1,...,e_n~iid~\NN(0,\sigma^2)$ a~$\beta_1=0$ (platí $H_0:~\beta_1=0$) v~modelu, potom  $\mathrm{F}\sim\mathrm{F}(1,n-2)$.
	\end{enumerate}
\begin{proof}
	Důkaz věty bude založen na~rozkladu
	$$ \sumin (y_i-\lyn)^2=\sumin(\hyi-\ly)^2 + \sumin (y_i-\hyi)^2 $$ neboli $\SST=\SSR+\SSE$. Z~lemmatu \ref{lemma_k_vete} vyplývá, že 
	\[
	\begin{split}
	\SST&=\sumin (y_i-\lyn)^2=\sumin\big[ (y_i-\hyi)+(\hyi-\lyn) \big]^2=\\&=\sumin(y_i-\hyi)^2+\sumin(\hyi-\lyn)^2+2\sumin(y_i-\hyi)(\hyi-\lyn)=\SSE+\SSR+0 ,
	\end{split}
	\]
	neboť $$ \sumin(\underbrace{(y_i-\hyi)}_{=\hei}(\hyi-\lyn))=\underbrace{\sumin\hei\hyi}_{=0}-\lyn\underbrace{\sumin\hei}_{=0}=0.$$
	Z toho potom dokazujeme jednotlivé body věty. \begin{enumerate}
		\item Protože $\SST=\SSE+\SSR$, pak $0\leq \RMR^2=\frac{\SSR}{\SST}\leq \frac{\SST}{\SST}=1$.
		\item $\SSR=\SST-\SSE~\Rightarrow~\RMR^2=\frac{\SST-\SSE}{\SST}=1-\frac{\SSE}{\SST}$.
		\item Z~bodu 2 plyne, že $\RMR^2=1~\Leftrightarrow~\SSE=0$ a~$\SSE=\sumin(y_i-\hyi)^2=0~\Leftrightarrow~y_i=\hyi ~\forall i~\in\hat{n}$.
		\item  $\hyi=\underbrace{\wbeta_0}_{=\lyn=\wbeta_1 x_n} + \wbeta_1 x_i=\lyn-\wbeta_1(\overline{x}_n-x_i)$. Proto pak $$ \SSR=\sumin(\hyi-\hyn)^2+\wbeta_1^2\sumin(x_i-\overline{x}_n)^2=\wbeta_1^2 S_{xx},$$ a~protože $\wbeta_1=\frac{1}{S_{xx}}\sumin(x_i-\overline{x}_n)(y_i-\lyn)$, dostaneme 
		$$ \rho^2(\textbf{x},\textbf{y})=\frac{\Big[\sumin(x_i-\overline{x}_n)(y_i-\lyn)\Big]^2}{S_{xx}S_{yy}}=\frac{\wbeta_1^2 S_{xx}}{S_{yy}}=\frac{\SSR}{\SST}=\RMR^2, $$ neboť $S_{yy}=\sumin(y_i-\lyn)^2=\SST$.
		\item Z~definice $\mathrm{F}$ plyne, že 
		$$ \mathrm{F}=\frac{(n-2)\RMR^2}{1-\RMR^2}=\frac{(n-2)\frac{\SSR}{\SST}}{\frac{\SSE}{\SST}}=\frac{\SSR}{\frac{\SSE}{n-2}}=\frac{\SSR}{s_n^2}. $$ Protože $T_n=\wbeta_1\frac{\sqrt{S_{xx}}}{s_n}$, pak $$ \mathrm{T}^2=\frac{\wbeta_1^2 S_{xx}}{s_n^2}=\frac{\SSR}{s_n^2}=\mathrm{F}. $$
		\item $T\sim t(n-2)~\Rightarrow~\mathrm{F}=\mathrm{T}^2\sim\mathrm{F}(1,n-2)$.
		
	\end{enumerate}
\end{proof}
\end{theorem}
\begin{remark}
\begin{enumerate}
	\item 	Z bodů 5 a~6 vyplývá, že použití libovolné statistiky $T_n,\RMR^2$ nebo $\mathrm{F}$ vede na~ekvivalentní test významnosti regrese.
	\item $\RMR^2$ poskytuje hrubou představu o~kvalitě modelu, čím je blíže $1$, tím lépe přímka prokládá data (nicméně je třeba jisté obezřetnosti, jak uvidíme později).
	\item $\mathrm{F}$ lze chápat jako statistiku pro~test významnosti velkých hodnot $\RMR^2$.
\end{enumerate}
\end{remark}
Výsledky se~většinou uvádí v~tabulce ANOVA:
\begin{table}[h]\label{ANOVA_table}
	\begin{tabular}{|lllll|}
	\hline
	Source & df & SS & MS & F\\
	\hline
	Regression & 1 & SSR & MSR=SSR & $\frac{\mathrm{MSR}}{\mathrm{MSE}}$ \\
	Residual & $n-2$ & SSE & $\mathrm{MSE}=\frac{\mathrm{SSE}}{n-2}=s_n^2$ & \\
	Total & $n-1$ & SST & & \\ \hline
\end{tabular}
\end{table}

$$\RMR^2=\frac{\SSR}{\SST}$$
Kde \textbf{source} je zdroj součtu čtverců, \textbf{df} počet stupňů volnosti příslušný danému součtu čtverců, \textbf{SS} počet čtverců a~\textbf{MS} $(\mathrm{MS}=\frac{\mathrm{SS}}{\mathrm{df}})$ "mean squares". 
\begin{remark}
	$H_0:~\beta_1=0$ je zamítnul, pokud $\mathrm{F}>\mathrm{F}_{1-\alpha}(1,n-2)$. V~tomto jednorozměrném případě je to ekvivalentní $t$-testu, neboť $\mathrm{F}=\mathrm{T}^2$.
\end{remark} 
\begin{theorem}
	Mějme $e_1,...,e_n~iid~\NN(0,\sigma^2)$. Za~platnosti $H_0:~\beta_1=0$ je splněno, že
	$$ \frac{\SSR}{\sigma^2}\sim\chi^2(1),\qquad\frac{\SSE}{\sigma^2}\sim\chi^2(n-2),\qquad\frac{\SST}{\sigma^2}\sim\chi^2(n-1). $$
\end{theorem}
\begin{remark}
	Proto v~tabulce ANOVA \ref{ANOVA_table} uvádí df po~řadě $1,n-2,n-1$. Používají se~však i~v případě jiného rozdělení chyb. Představit si je lze takto:\begin{enumerate}
		\item $\SSE=\sumin\hei^2$, na~$n$-rezidní $\he_1,...,\he_n$ máme 2 podmínky $\sumin\hei=0$ a~$\sumin x_i\hei=0$. Z~toho vyplývá, že mají $n-2$ stupňů volnosti.
		\item $\SST=\sumin(y_i-\lyn)^2$... $y_i-\lyn$ musí splňovat $\sumin(y_i-\lyn)=0$, a~proto má $n-1$ stupňů volnosti.
		\item $\SSR=\SST-\SSE$, a~počet stupňůů volnosti je roven $(n-1)-(n-2)=1$.
	\end{enumerate} 
\begin{proof}
	V důkazu věty ?? jsme ukázali, že $\SSR=\wbeta_1^2 S_{xx}$, takže $\frac{\SSR}{\sigma^2}=\Big( \frac{\wbeta_1\sqrt{S_{xx}}}{\sigma} \Big)^2$, víme, že $\wbeta_1\sim\NN\big(\beta_1,\frac{\sigma^2}{S_{xx}}\big)$ a~tedy $(\wbeta_1-\beta_1)\frac{S_{xx}}{\sigma}\sim\NN(0,1)$. Pro~$\beta_1=0$ tedy $$\wbeta_1\frac{\sqrt{S_{xx}}}{\sigma}\sim\NN(0,1)~\Rightarrow~\frac{\SSR}{\sigma^2}\sim\chi^2(1).$$
	Zároveň také $\frac{\SSE}{\sigma^2}=\frac{(n-2)s_n^2}{\sigma^2}\sim\chi^2(n-2)$ (viz dříve) a~nezávisí na~$\wbeta_1$. Z~toho vyplývá, že $\frac{\SSR}{\sigma^2}$ a~$\frac{\SSE}{\sigma^2}$ jsou nezávislé. Dále platí, že 
	$$ \frac{\SST}{\sigma^2}=\frac{\SSR}{\sigma^2}+\frac{\SSE}{\sigma^2}~\Rightarrow~\frac{\SST}{\sigma^2}\sim\chi^2(n-1).$$
\end{proof}
\end{remark}
\begin{remark}
	$\RMR^2$ statistika - pozor na~zjednodušení kvality modelu. \begin{enumerate}
		\item Nízké hodnoty $\RMR^2$ nemusí znamenat, že regresní model není významný. V~datech jen může být velké množství nevysvětlitelné náhodné variability. Například opakování hodnoty regresoru $x$ snižují hodnotu $\RMR^2$ oproti~modelům s~různými $x$.
		\item Velké hodnoty $\RMR^2$ mohou být způsobeny velkým měřítkem dat ($S_{xx}$ je velká). Platí totiž, že 
		$$ \E(\RMR^2)\approx\frac{\beta_1^2 S_{xx}}{\beta_1^2 S_{xx}+\sigma^2},$$ což je rostoucí funkce $S_{xx}$.
		
		Velký rozptyl $(x_1,...,x_n)$ může mít za~následek velké $\RMR^2$ a~přitom nic neříká o~kvalitě modelu.
		
		$\E(\RMR^2)$ je také rostoucí funkcí $\beta_1^2$. Modely s~$velkou$ směrnicí tedy budou mít obecně větší $yRMR^2$, než modely s~"malou" směrnicí. 
	\end{enumerate}
\end{remark}

Při hodnocení kvality modelu potřebujeme více kritérií. Mezi~ně patří například\begin{enumerate}
	\item "velké" $\RMR^2$,
	\item "velké" $\mathrm{F}$ nebo $|\mathrm{T}|$ hodnoty,
	\item "malé" hodnoty $s_n^2$ vzhledem k~$\lyn$.
\end{enumerate}
Další kritéria budeme probírat později.
\begin{example}
	Velká hodnota $\RMR^2$ indikuje přibližně lineární vztah mezi~$x$ a~$y$, ale vysoký stupeň korelace nemusí znamenat příčinný vztah.
	data: 1924-1937
	
	$y_i$ - počet mentálních onemocnění na~$100000$ obyvatel Anglie.\\
	$x_i$ - počet rádií v~populaci.\\
	model - $y_i=\beta_0+\beta_1 x_i+e_i$.
	$$ \wbeta_0=4.5822,\qquad\wbeta_1=2.2042,\qquad\RMR^2=0.984,$$
	tzv. velmi významný lineární vztah mezi~$x$ a~$y$. Závěr by mohl být, že rádia způsobují mentální onemocnění. I~když by to mohla být pravda, nabízí se~věrohodnější vysvětlení, a~to takové, že $x$ i~$y$ rostou lineárně s~časem, tzn. $y$ roste lineárně s~$x$. 
	
	Rádia byla s~časem dostupnější, lepší diagnostické procedury umožňovaly identifikovat více lidí s~mentálními problémy.
\end{example}