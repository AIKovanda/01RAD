% pages 31-35
\begin{remark}
 korelace VS příčinnost
 
 \begin{itemize}
  \item \textbf{Příčinná spojitost} - i když je příčinná spojitost mezi $ x $ a $ y $ korelace samotná nám neřekne, zda $ x $ ovlivňuje $ y $ nebo naopak.
  \item \textbf{Skrytá příčinnost} - skrytá veličina $ z $ ovlivňuje $ x $ i $ y $, což způsobuje jejich korelovanost.
  \item \textbf{Confounding factor} - skryté proměnné $ z $ i $ x $ ovlivňují $ y $, výsledek tedy závisí i na $ z $.
  \item \textbf{Coincidence} - korelace je náhodná.
\end{itemize}
\end{remark}

\section{Regrese skrz počátek}
Existují případy, kdy přípustný model vyžaduje $ \beta_0 = 0 $, tj. 
$$
 Y_i = \beta_1 x_i + e_i \, , \quad \text{kde} \quad i = 1,\dots,n
$$

\begin{example}
 \begin{itemize}
  \item Je to předem známo na základě nějakých fyzikálních úvah 
  $$
 \E [Y_0] = \beta_0 = 0
$$
		potom nemá smysl odhadnout $ \beta_0 $, protože to obecně sníží přesnost odhadu $ \sigma^{2} $ a tedy i $ \beta_1 $
  \item Na začátek předpokládáme, že $ \beta_0 \neq 0 $ a t-test nezamítne hypotézu $ \text{H}_0 \, : \, \beta_0 = 0 $, potom $ \beta_0 $ může být z modelu odstraněn.
\end{itemize}
\end{example}

\begin{remark}
V praktických situacích si často nemůžeme být jisti, že model platí i blízko počátku. Část statistiků trvá na přítomnosti interceptu v modelu, i když je nevýznamný.

Položit $ \beta_0 $ apriorně, může nýt chybné i když $ \E [ Y_0 ] = 0 $. Pokud totiž nevíme jistě, že model je lineární na okolí 0, volba $ \beta_0 = 0 $ může vést k vychýleným odhadům $ \beta_1 $, pokud jsou nezávislé proměnné daleko od $ x = 0 $.
\end{remark}

----------------PICTURE----------------------

\subsection{Odhady a testy v případě $ \beta_0 = 0 $}
LSE parametru $ \beta_1 $ dostaneme minimalizací $ S = \sumin ( y_i - \beta_1 x_i )^{2}  $ ve tvaru: 
$$ 
 \widehat{\beta}_{1} = \dfrac{\sumin  y_i  x_i }{\sumin x_i^{2}},
$$
pokud $ e_1,\dots , e_n  $ i.i.d. $ N(0,\sigma^{2}) $, potom $ \E [ \widehat{\beta}_{1} ] = \beta_1 $ a $ \D [ \widehat{\beta}_{1}  ] = \frac{\sigma^{2}}{\sumin x_i^{2}} $.
Takže $  \widehat{\beta}_{1} \sim N(\beta_1 , \frac{\sigma^{2}}{\sumin x_i^{2}}) $
a $ s_n^{2} = \dfrac{\sumin (y_i -  \widehat{y}_i)^{2}}{n-1} = \dfrac{\SSE}{n-1} $ je nestranný odhad $ \sigma^{2} $.
Dále $ \frac{\SSE}{\sigma^{2}} \sim \chi^{2}(n-1) $ a nezávisí na $ \widehat{\beta}_{1} $.
$ \text{H}_0 \, : \, \beta_1 = 0 $ lze otestovat za pomoci statistiky:
$$ 
  T = \dfrac{\widehat{\beta}_{1}}{\dfrac{s_n}{\sqrt{\sum x_i^{2}}}} \sim \text{t}(n-1)
$$

$ 100(1-\alpha) \% $ IS pro $ \beta_1 $ je $ (\widehat{\beta}_{1} \pm \text{t}_{1 - \dfrac{\alpha}{2}}(n-1)\dfrac{s_n}{\sqrt{\sum x_i^{2}}}) $
\begin{itemize}
  \item Zatím je vše podobné jako pro případ $ \beta_1 \neq 0 $.
  \item Rozdíl je ale v tabulce ANOVA a v míře dobré shody, problém je, že neplatí rozklad $ \SST = SSR + SSE $ neboť součet reziduí $ \sumin (y_i - \widehat{y}) $ nemusí být 0 a tedy $ \overline{\widehat{y}}_n \neq \overline{y}_n $.
  Odvodíme nový rozklad, který platí v obou případech, dokážeme ho ale jen pro $ \beta_0 = 0 $
\end{itemize}

\begin{theorem}
V modelu s $ \beta_0 = 0 $ platí
$$ 
 \sumin y_i^{2} = \sumin \widehat{y}_i^{2} + \sumin ( y_i - \widehat{y}_i )^{2}
$$
\end{theorem}

\begin{proof}
$$ 
 \sumin y_i^{2} = \sumin (y_i - \widehat{y}_i + \widehat{y}_i )^{2} = \sumin ( y_i - \widehat{y}_i )^{2} + \sumin \widehat{y}_i^{2} + 2 \sumin ( y_i - \widehat{y}_i ) \widehat{y}_i 
 $$
 $$
 \text{z rovnice}  \quad  \dfrac{\d S}{\d \beta_1} = 0  \quad  \text{dostaneme}  \quad \sumin ( y_i - \widehat{\beta}_1 x_i) x_i = 0
$$
 $$
 \sumin ( y_i - \widehat{y}_i ) \widehat{y}_i  = 0  \quad \text{Q. E. D.}
$$
\end{proof}
Pokud vezmeme $ \sum y_i^{2} $ jako míru variability v datech, analogie $ \text{R}^{2} $ statistiky bude

$$ 
  \text{R}^{2} = \dfrac{\sumin \widehat{y}_i^{2}}{\sumin y_i^{2}} \quad \Leftrightarrow \quad
  1 - \text{R}^{2} = \dfrac{\sumin y_i^{2} - \sumin \widehat{y}_i^{2}}{\sumin y_i^{2}} = \dfrac{\sumin \widehat{e}_i^{2}}{\sumin y_i^{2} }
$$
=definujeme $ \FF = \dfrac{(n-1) \text{R}^{2}}{1 - \text{R}^{2}} $ potom 
$$ 
  \FF = \dfrac{\sumin \widehat{y}_i^{2} }{\frac{1}{n-1} \sumin ( y_i - \widehat{y}_i )^{2} } = \dfrac{\widehat{\beta}_{1} \sumin x_i^{2} }{ s_n^{2}}= \text{T}^{2}
$$

vztah mezi $ \text{R}^{2}, \FF \text{ a T}^{2} $ je tedy stejný jako pro $ \beta_0 \neq 0 $.

\begin{remark}
  Tato definice $ \text{R}^{2} $ se ale v praxi moc nepoužívá, protože neumožňuje přímé srovnání modelů bez a s interceptem.
\end{remark}

\noindent\begin{minipage}{.5\linewidth}
$$
  \beta_0 = 0 \quad : \quad \text{R}^{2} = 1 - \dfrac{\SSE}{\sumin y_i^{2}}
$$
\end{minipage}%
\begin{minipage}{.5\linewidth}
$$
  \beta_0 \neq 0 \quad : \quad \text{R}^{2} = 1 - \dfrac{\SSE}{\sumin (y_i - \oynn)^{2}}
$$
\end{minipage}

obecně ale $ \sumin (y_i - \oynn)^{2} < \sumin y_i^{2} $, $ \text{R}^{2} $ v modelu s $ \beta_0 = 0 $ tedy bude větší než $ \text{R}^{2} $ modelu s $ \beta_0 \neq 0 $ i když jsou jejich $ \SSE $ srovnatelné.

\begin{itemize}
  \item Definice vhodné $ \text{R}^{2} $ pro $ \beta_0 = 0 $ vyvolává jistou kontroverzi a existuje několik verzí.
  \item Možná volba je $ \text{R}^{2} = ( \rho (y_I, \overline{y}_{I}  ))^{2} $, kde $ \overline{y}_{I} = ( \overline{y}_{1},\dots ,\overline{y}_{n}) $ protože tato vlastnost platí i pro případ $ \beta_0 = 0 $.
  \item Další možnost je srovnat modely pomocí hodnot $ s_n^{2} $. (preferuje se model s nejnižší hodnotou $ s_n^{2} $)
\end{itemize}