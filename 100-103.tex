\subsection{BOX-COX transformace}
\begin{itemize}
\item Pokud chyby nemají normální rozdělení, hledáme transformaci Y, která by nejenom linearizovala model, ale také transformovala chyby, aby byly přibližně normální.
\item Jako užitečná se ukazuje následující třída transformací (power family)
$$
 y^{(\lambda)} = \begin{cases}
      \frac{y^{\lambda}-1}{\lambda}, & \text{pokud}\ \lambda \neq 0 \\
      \text{log}y, & \text{pokud}\ \lambda = 0
    \end{cases} \, ,
$$
které předpokládají, že data $ y $ jsou pouze kladná. (pokud ne, můžeme přičíst konstantu ke všem pozorováním a analyzovat takto posunutá data)
\begin{remark}
$ \lim_{\lambda \rightarrow 0}  \frac{y^{\lambda}-1}{\lambda} = \text{log}y $
\end{remark}
\item Pro nalezení vlastního $ \lambda $ budeme předpokládat, že transformované veličiny $ Y_i^{(\lambda)}, \, i = 1,\dots,n, $ splňují postačující podmínky RM, tj. 
$$
 Y_i^{(\lambda)} = \x_i^T \bbeta + \eb \quad \text{kde} \quad \eb \sim \NN_n (0,\sigma^2 \Identita{n}) \quad \dots \quad ( Y_i^{(\lambda)} \sim \NN ( \X_i^T \bbeta , \sigma^2 ))
$$
\end{itemize}
Úkol je odhadnout zároveň $ \lambda , \bbeta , \sigma^2 $, použijeme MLE pomocí transformace získáme hustotu
$$
  f_{Y_i}(y_i) = f_{Y_i^{(\lambda)}}(y_i^{(\lambda)}) \cdot \dfrac{\d y_i^{(\lambda)}}{\d y_i} = \dfrac{1}{\sqrt{2 \pi \sigma^2}} e^{-\frac{1}{2 \sigma^2}( y_i^{(\lambda)} - \mu_i)^2} \cdot y_i^{\lambda - 1}, \quad \text{kde} \quad \mu_i = \E[Y_i^{(\lambda)}] = \x_i^T \bbeta
$$
věrohodnostní funkce pro pozorování $ y_1,\dots,y_n $ bude
$$
  L = \prod_{i=1}^{n}f_{Y_i}(y_i) = \left( \frac{1}{\sqrt{2 \pi \sigma^2}} \right)^2 e^{-\frac{1}{2 \sigma^2}(\sumin ( y_i^{(\lambda)} - \mu_i )^2} \cdot \text{J}(\lambda), \quad \text{kde} \quad \text{J}(\lambda) = \prod_{i=1}^{n} y_i^{\lambda - 1} = \left( \prod_{i=1}^{n} y_i \right)^{\lambda - 1}
$$

log - likelihood:
$$
 l = \text{ln}L = -\frac{n}{2}\text{ln} 2 \pi - \frac{n}{2}\text{ln} \sigma^2 - \frac{1}{2 \sigma^2} \sumin ( y_i^{(\lambda)} - \mu_i )^2 + \text{ln}\text{J}(\lambda)
$$
věrohodnostní rovnice nemají explicitní analytické řešení, pro nalezení MLE si všimneme, že pro pevné $ \lambda $ je $ l $ proporcionální logaritmus věrohodnosti pro odhad ($ \bbeta , \sigma^2 $) na základě $ \y^{(\lambda)} = ( y_1^{(\lambda)}, \dots , y_n^{(\lambda)})^T $, tedy
$$
 \wbetab (\lambda ) = \core \X^T \y^{(\lambda)}
$$
$$
 \wsigma^2 (\lambda ) = \frac{1}{n} \sumin ( y_i^{(\lambda)} - \hy _i^{(\lambda)} )^2 = \frac{1}{n} (\y^{(\lambda)})^T ( \I _n - \Hm ) \y^{(\lambda)} , \quad \text{kde} \quad \hy_i^{(\lambda)} = \x_i^T \bbeta^{(\lambda)}
$$
Dosazením do $ l $ dostaneme její hodnotu maximalizovanou vzhledem k ( $ \bbeta , \sigma^2 $ ), tzv. profite log - likelihood
$$
  l_p^{(\lambda)} = -\frac{n}{2} \text{ln} 2 \pi - \frac{n}{2} \text{ln} \wsigma^2 ( \lambda ) - \frac{n}{2} + \text{ln} \text{J}(\lambda) 
  = C - \frac{n}{2} \text{ln} \wsigma^2 ( \lambda ) + ( \lambda - 1 )  \sumin \text{ln} y_i
$$
\begin{remark}
 kvůli komplikované závislosti $ l_p $ na $ \lambda $ bude třeba numerická metoda pro maximalizaci. Lze přepsat do tvaru, kde bude možné využít metody LR.
\end{remark}
$$
 l_p (\lambda) =  C - \frac{n}{2} \text{ln} \wsigma^2 ( \lambda )  - \frac{n}{2} \text{ln}\text{J}(\lambda) = C - \frac{n}{2} \text{ln} \frac{ \wsigma^2 ( \lambda )}{(\text{J}^{\frac{1}{n}}(\lambda))^2} 
$$
$$
 (\text{J}^{\frac{1}{n}}(\lambda)) = \left[ \left( \prod_{i=1}^{n} y_i \right)^{\frac{1}{n}} \right]^{\lambda - 1} = ( \dot{y} )^{\lambda - 1} \quad \text{kde} \, \dot{y} \, \text{je geometrický průměr}
$$
$$
\text{tzn.} \quad  l_p(\lambda) = C - \frac{n}{2} \text{ln} \frac{ \wsigma^2 ( \lambda )}{(\dot{y})^{\lambda - 1}} = C - \frac{n}{2}\text{ln} s_{\lambda}^{2} 
$$
$$
\text{kde} \quad s_{\lambda}^{2} = \frac{ \wsigma^2 ( \lambda )}{(\dot{y})^{\lambda - 1}} = \frac{1}{n} \sumin \left( \frac{y_i^{(\lambda)}}{( \dot{y})^{\lambda-1}} - \frac{\hy_i^{(\lambda)}}{( \dot{y})^{\lambda-1}} \right)^2
$$
tzn. $ s_{\lambda}^{2} $ je reziduální součet čtverců (SSE) v modelu $ \frac{y_i^{(\lambda)}}{( \dot{y})^{\lambda-1}} $ v závislosti na $ \x_i^T $ (tzn. $ s_{\lambda}^{2} $ lze snadno získat pomocí funkce ln( )) \\
Celkem: max $ l_p(\lambda) \quad \Leftrightarrow \quad $ min $ s_{\lambda}^{2} $ \\
Algoritmus: \\
\begin{enumerate}
\item Zvolit oblast hodnot $ \lambda $, I = $ [ \lambda_{min}, \lambda_{max} ] $, a body $ \lambda \in $ I \\
(typicky I = [-2,2] a 10-20 rovnoměrně rozdělených bodů)
\item Naladit model $ \frac{y^{(\lambda)}}{( \dot{y})^{\lambda-1}} \sim \chi $ a spočítat $ \frac{1}{n}\SSE = s_{\lambda}^{2} $.
\item Z grafu ($ \lambda , s_{\lambda}^{2} $) vybrat $ \widehat{\lambda} $, které minimalizuje $ s_{\lambda}^{2} $
\item Pro zvolené $ \widehat{\lambda} $ naladit model $ y^{(\widehat{\lambda})} \sim \chi $ a pokračovat standardní analýzou.
\end{enumerate}
IS pro $ \lambda $: \\
Snadno lze odvodit LRT test pro test $ \text{H}_0 : \quad \lambda = \lambda_0 $. ($ \text{H}_0 : \quad \lambda = 1 $ zde je třeba transformace pokud zamítneme $ \text{H}_0 \Rightarrow $ transformace pomocí $ \widehat{\lambda} $) \\
LRT statistika $ \Lambda = -2 \text{ln} \frac{L(\lambda_0}{L(\widehat{\lambda}} = 2 ( l_p(\widehat{\lambda}) - l_p(\lambda_0)) $. Víme že $ \Lambda \Lp \chi^2(1)  $. Invertováním příslušné oblsti LRT testu, dostaneme as. $ 100(1-\alpha)\% $ IS pro $ \lambda $
$$
  \Lambda \leq \chi^2_{1-\alpha}
$$
$$
 2( \frac{n}{n}\text{ln}s^2_{\lambda_0} - \frac{n}{n}\text{ln}s^2_{\widehat{\lambda}}  ) \leq \chi^2_{1-\alpha}
$$
$$
  n \text{ln}\dfrac{s^2_{\lambda_0}}{s^2_{\widehat{\lambda}}} \leq \chi^2_{1-\alpha}
$$
Pokud $ \widehat{\lambda} $ je MLE $ \lambda $, as. $ 100(1-\alpha)\% $ IS  pro $ \lambda $ je:
$$
 \left\{ \lambda \in \R \, \vert \, n \cdot \text{ln}\dfrac{s^2_{\lambda_0}}{s^2_{\widehat{\lambda}}} \leq \chi^2_{1-\alpha}(1) \right\} 
$$
\begin{remark}
 Kvůli jednoduchosti interpretace se často doporučuje zaokrouhlit $ \widehat{\lambda} $ na nejbližší $ \dfrac{1}{4} $ nebo $ \dfrac{1}{3} $.
\end{remark}
Příklad data TREES
\subsection{Transformace vysvětlujících proměnných x}
\begin{itemize}
\item Pokud diagnostika modelu naznačuje, že vztah mezi $ \y $ a $ \X $ není lineární pro jeden nebo více regresorů, může být vhodné přeformovat model pomocí transformací proměnných $ \x $.
\item Předpokládejme, že v modelu $ Y = \beta_0 + \sumjm \beta_j x_j + e $ máme podezření na nelinearitu v j-té proměnné $ x_j $.
\item Jedenu z možností jak postupovat jr nahrazení $ x_j $ proměnnou $ z_j = f(x_j) $, model tedy bude $ Y = \beta_0 + \beta_1 x_1 + \dots + \beta_j z_j + \dots + \beta_m x_m + e $.
\item Pokud je $ f $ známé, jedná se o model LR a lze ho analyzovat standardně. \\
Pokud je tato transformace vhodná, mělo by se to projevit ve zlepšení statistik $ \text{R}^2, \text{t}, \text{F} $ a zlepšení grafu reziduí pro $ z_j $ oproti těm pro $ x_j $.
\item Bohužel $ f $ většinou známá není, možný přístup je parametrizovat nějak tuto funkci a pak odhadnout tyto parametry společně s $ \bbeta $.
\end{itemize}

\begin{itemize}
\item Typická parametrizace: 
$$
  z_j = x_j^{\lambda}, \quad \text{kde} \quad \lambda \in \R \quad \text{vhodné}.
$$
( $ x_j > $ potom $ \lambda \in \R $, pokud $ x_j $ může být záporné, množina hodnot $ \lambda $ je omezená)
\item Aproximace $ f $ pomocí polynomu vhodného stupně, tzn. 
$$
  z_j = \sum_{k=1}^{l} r_k x_j^{k} , \quad \text{kde} \, r_k \, \text{musí být odhadnuty,}
$$
Výsledný model ale v tomto případě nebude lineární v parametrech $ \beta_j $ $ j = 0,\dots,m $ a $ r_k $, $ k = 1,\dots,l $.
\end{itemize}